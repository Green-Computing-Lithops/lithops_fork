# Ejecutar SimulaciÃ³n de Costes con Dockerfile Oficial de Lithops

Esta guÃ­a te explica cÃ³mo usar el [Dockerfile oficial de Lithops](https://github.com/lithops-cloud/lithops/blob/master/runtime/aws_lambda/Dockerfile) para crear un runtime personalizado que incluya tu simulaciÃ³n de costes.

## ğŸ¯ **Objetivo**

Crear un runtime personalizado de AWS Lambda que:
- âœ… Use el Dockerfile oficial de Lithops
- âœ… Incluya tu cÃ³digo de simulaciÃ³n de costes
- âœ… Permita ejecutar workloads con estimaciÃ³n previa
- âœ… Sea deployable y reutilizable

## ğŸ“‚ **Estructura de archivos necesarios**

```
proyecto/
â”œâ”€â”€ Dockerfile.lithops-costes     # Dockerfile personalizado
â”œâ”€â”€ lithops_config.yaml          # ConfiguraciÃ³n de Lithops
â”œâ”€â”€ main_german_container.py     # Tu funciÃ³n adaptada para container
â”œâ”€â”€ simulacion_costes.py         # MÃ³dulo de simulaciÃ³n
â”œâ”€â”€ requirements.txt             # Dependencias extra
â””â”€â”€ deploy_runtime.sh            # Script de despliegue
```

## ğŸ³ **1. Dockerfile personalizado**

Basado en el [Dockerfile oficial](https://github.com/lithops-cloud/lithops/blob/master/runtime/aws_lambda/Dockerfile):

```dockerfile
# Dockerfile.lithops-costes
# Basado en: https://github.com/lithops-cloud/lithops/blob/master/runtime/aws_lambda/Dockerfile

# Python 3.10 (versiÃ³n recomendada)
FROM python:3.10-slim-buster

RUN apt-get update \
    # Install aws-lambda-cpp build dependencies
    && apt-get install -y \
      g++ \
      make \
      cmake \
      unzip \
    # cleanup package lists
    && rm -rf /var/lib/apt/lists/* \
    && apt-cache search linux-headers-generic

ARG FUNCTION_DIR="/function"

# Copy function code
RUN mkdir -p ${FUNCTION_DIR}

# Update pip - DEPENDENCIAS OFICIALES DE LITHOPS
RUN pip install --upgrade --ignore-installed pip wheel six setuptools \
    && pip install --upgrade --no-cache-dir --ignore-installed \
        awslambdaric \
        boto3 \
        redis \
        httplib2 \
        requests \
        numpy \
        scipy \
        pandas \
        pika \
        kafka-python \
        cloudpickle \
        ps-mem \
        tblib \
        psutil

# Set working directory to function root directory
WORKDIR ${FUNCTION_DIR}

# Add Lithops (esto se hace automÃ¡ticamente por Lithops CLI)
COPY lithops_lambda.zip ${FUNCTION_DIR}
RUN unzip lithops_lambda.zip \
    && rm lithops_lambda.zip \
    && mkdir handler \
    && touch handler/__init__.py \
    && mv entry_point.py handler/

# ğŸ†• AÃ‘ADIR NUESTROS MÃ“DULOS DE SIMULACIÃ“N
COPY simulacion_costes.py ${FUNCTION_DIR}/
COPY main_german_container.py ${FUNCTION_DIR}/

# ğŸ†• DEPENDENCIAS ADICIONALES (si las necesitas)
COPY requirements.txt ${FUNCTION_DIR}/
RUN pip install --no-cache-dir -r requirements.txt

ENTRYPOINT [ "/usr/local/bin/python", "-m", "awslambdaric" ]
CMD [ "handler.entry_point.lambda_handler" ]
```

## âš™ï¸ **2. ConfiguraciÃ³n de Lithops**

```yaml
# lithops_config.yaml
lithops:
    backend: aws_lambda
    storage: aws_s3

aws:
    access_key_id: YOUR_ACCESS_KEY_ID
    secret_access_key: YOUR_SECRET_ACCESS_KEY
    region: us-east-1

aws_lambda:
    execution_role: arn:aws:iam::YOUR_ACCOUNT:role/lithops-execution-role
    runtime: lithops-costes-runtime:latest
    runtime_memory: 256
    runtime_timeout: 300

aws_s3:
    bucket: lithops-us-east-1-45dk
```

## ğŸ **3. Tu funciÃ³n adaptada para container**

```python
# main_german_container.py
import lithops
from lithops.storage import Storage
from simulacion_costes import calcular_coste_aws_lambda, mostrar_simulacion_costes
import time
from datetime import datetime

def funcion_german_con_simulacion(x):
    """
    Tu funciÃ³n original con capacidad de simulaciÃ³n incluida
    """
    storage = Storage()
    try:
        bucket_name = "lithops-us-east-1-45dk"
        
        test_key = f"test-execution/test-file-{x}.txt"
        test_data = f"Hello from AWS Lambda task {x}"
        storage.put_object(bucket_name, test_key, test_data)
        print(f"Created test file in S3: {bucket_name}/{test_key}")
        
        keys = storage.list_keys(bucket_name, prefix="test-execution/")
        print(f"Found keys in {bucket_name}: {keys}")
        
        result = storage.get_object(bucket_name, test_key)
        print(f"Read back from S3: {result}")
        
    except Exception as e:
        print(f"AWS S3 operation failed: {e}")
        import traceback
        traceback.print_exc()
    
    return x + 1

def ejecutar_con_simulacion():
    """
    FunciÃ³n principal que incluye simulaciÃ³n de costes
    """
    # Datos de entrada
    datos = [1, 2, 3]
    
    # ğŸ§® SIMULACIÃ“N DE COSTES
    print("ğŸ§® Realizando simulaciÃ³n de costes...")
    simulacion = calcular_coste_aws_lambda(
        num_invocaciones=len(datos),
        memoria_mb=256,
        duracion_estimada_ms=2000
    )
    
    mostrar_simulacion_costes(simulacion)
    
    # Crear executor
    executor = lithops.FunctionExecutor()
    
    # â° Medir tiempo de ejecuciÃ³n
    inicio = time.time()
    
    # Ejecutar funciones
    futures = executor.map(funcion_german_con_simulacion, datos)
    resultados = executor.get_result(futures)
    
    fin = time.time()
    duracion_real = (fin - inicio) * 1000  # en ms
    
    print(f"\nâœ… EJECUCIÃ“N COMPLETADA")
    print(f"ğŸ“Š Resultados: {resultados}")
    print(f"â±ï¸  DuraciÃ³n real: {duracion_real:.2f} ms")
    
    # ğŸ”„ Recalcular con duraciÃ³n real
    print("\nğŸ”„ Costes con duraciÃ³n real:")
    simulacion_real = calcular_coste_aws_lambda(
        num_invocaciones=len(datos),
        memoria_mb=256,
        duracion_estimada_ms=int(duracion_real / len(datos))
    )
    
    print(f"   Estimado: ${simulacion['total']['coste_total_usd']}")
    print(f"   Real: ${simulacion_real['total']['coste_total_usd']}")
    
    return resultados

if __name__ == "__main__":
    ejecutar_con_simulacion()
```

## ğŸ“¦ **4. Requirements adicionales**

```txt
# requirements.txt
# AquÃ­ puedes aÃ±adir dependencias extra que no estÃ¡n en el Dockerfile base
# Por ejemplo:
# matplotlib>=3.5.0
# scikit-learn>=1.0.0
# opencv-python-headless>=4.5.0
```

## ğŸš€ **5. Script de despliegue**

```bash
#!/bin/bash
# deploy_runtime.sh

echo "ğŸ³ Construyendo runtime personalizado con simulaciÃ³n de costes..."

# 1. Construir el runtime
lithops runtime build -f Dockerfile.lithops-costes -b aws_lambda lithops-costes-runtime:latest

# 2. Desplegar el runtime
lithops runtime deploy lithops-costes-runtime:latest -b aws_lambda

# 3. Listar runtimes disponibles
echo "ğŸ“‹ Runtimes disponibles:"
lithops runtime list -b aws_lambda

echo "âœ… Runtime desplegado. Ahora puedes ejecutar:"
echo "   python main_german_container.py"
```

## ğŸ› ï¸ **6. Pasos para ejecutar**

### **Paso 1: Preparar archivos**

```bash
# Crear directorio del proyecto
mkdir lithops-costes-runtime
cd lithops-costes-runtime

# Copiar los archivos que hemos creado
# - Dockerfile.lithops-costes
# - lithops_config.yaml  
# - main_german_container.py
# - simulacion_costes.py
# - requirements.txt
# - deploy_runtime.sh
```

### **Paso 2: Configurar credenciales AWS**

```bash
# OpciÃ³n 1: AWS CLI
aws configure

# OpciÃ³n 2: Variables de entorno
export AWS_ACCESS_KEY_ID="tu_access_key"
export AWS_SECRET_ACCESS_KEY="tu_secret_key"
export AWS_DEFAULT_REGION="us-east-1"
```

### **Paso 3: Instalar Lithops**

```bash
pip install lithops[aws]
```

### **Paso 4: Construir y desplegar**

```bash
# Dar permisos al script
chmod +x deploy_runtime.sh

# Ejecutar despliegue
./deploy_runtime.sh
```

### **Paso 5: Ejecutar con simulaciÃ³n**

```bash
# Ejecutar tu funciÃ³n con simulaciÃ³n integrada
python main_german_container.py
```

## ğŸ¯ **Ventajas de este enfoque**

1. **ğŸ“¦ Runtime reutilizable**: Una vez construido, puedes usarlo mÃºltiples veces
2. **ğŸ§® SimulaciÃ³n integrada**: Costes calculados automÃ¡ticamente
3. **âš¡ Optimizado**: Basado en el Dockerfile oficial de Lithops
4. **ğŸ”§ Personalizable**: Puedes aÃ±adir las dependencias que necesites
5. **ğŸ“Š Monitoreo**: Compara costes estimados vs reales

## ğŸ” **Ejemplo de salida esperada**

```
ğŸ§® Realizando simulaciÃ³n de costes...

============================================================
         SIMULACIÃ“N DE COSTES AWS LAMBDA + S3
============================================================

ğŸ“Š CONFIGURACIÃ“N:
   â€¢ Invocaciones: 3
   â€¢ Memoria: 256 MB
   â€¢ DuraciÃ³n estimada: 2000 ms
   â€¢ RegiÃ³n: us-east-1

ğŸ”§ AWS LAMBDA:
   â€¢ Requests totales: 3
   â€¢ Requests free tier: 3
   â€¢ Requests facturables: 0
   â€¢ Coste Lambda total: $0.0

ğŸ’¾ AWS S3:
   â€¢ Coste S3 total: $0.001004

ğŸ’° COSTE TOTAL ESTIMADO:
   â€¢ USD: $0.001004
   â€¢ EUR: â‚¬0.000924 (aprox.)

âœ… Coste muy bajo - menos de $0.01
============================================================

âœ… EJECUCIÃ“N COMPLETADA
ğŸ“Š Resultados: [2, 3, 4]
â±ï¸  DuraciÃ³n real: 1500.50 ms

ğŸ”„ Costes con duraciÃ³n real:
   Estimado: $0.001004
   Real: $0.001003
```

## ğŸš¨ **Troubleshooting**

### **Error: Docker no encontrado**
```bash
# Instalar Docker
# macOS: brew install docker
# Ubuntu: sudo apt install docker.io
```

### **Error: Credenciales AWS**
```bash
# Verificar credenciales
aws sts get-caller-identity
```

### **Error: Permisos ECR**
```bash
# Tu rol IAM necesita permisos para ECR
# AÃ±adir polÃ­tica: AmazonEC2ContainerRegistryFullAccess
```

## ğŸ“š **Referencias**

- [Dockerfile oficial de Lithops](https://github.com/lithops-cloud/lithops/blob/master/runtime/aws_lambda/Dockerfile)
- [DocumentaciÃ³n AWS Lambda Container Images](https://docs.aws.amazon.com/lambda/latest/dg/images-create.html)
- [Lithops Runtime Documentation](https://lithops-cloud.github.io/docs/)

---

ğŸ’¡ **Tip**: Este runtime personalizado te permite ejecutar cualquier workload con simulaciÃ³n de costes automÃ¡tica, ideal para producciÃ³n!
